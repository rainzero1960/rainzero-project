# KnowledgePaper

## アプリケーション概要と目的

KnowledgePaperは、論文の管理、検索、そして新しい知見の発見を、よりスマートにサポートするために開発されたアプリケーションです。あなたの研究活動を加速させるプラットフォームとなることを目指しています。

日々増え続ける論文情報を効率的に整理し、必要な情報へ素早くアクセスすることを可能にします。また、AI技術を活用することで、論文の理解を深め、新たな着想を得るお手伝いをします。

## 主要機能

-   **論文の追加と登録**:
    -   ArXivのURLから直接論文情報をインポートできます。
    -   Hugging Face Papersからの定期的な自動インポートも将来的に対応予定です。
-   **登録論文の一覧表示と高度な検索**:
    -   登録された論文を一覧で表示します。
    -   多彩なフィルタリングオプション（理解度タグ、分野タグ、キーワード検索）を利用できます。
    -   柔軟なソート機能（追加日、最終閲覧日、評価など）を備えています。
-   **AI (LLM) を活用した論文理解支援**:
    -   論文ごとに自動で要約を生成します（利用するAIモデルは選択可能です）。
    -   論文内容に関するインタラクティブなチャット形式でのQ&A機能があります（利用するAIモデルは選択可能です）。
-   **高度なRAG (Retrieval Augmented Generation) システム**:
    -   登録済み論文データベース全体を対象とした、意味を理解して検索する賢い検索（セマンティック検索）が可能です。
    -   Web検索機能との連携により、最新情報を取り込んだ回答を生成します。
    -   複数の検索モードを提供します:
        -   Simple RAG: 単純な質問応答を行います。
        -   Deep Research: 関連情報を深く掘り下げる調査します。
        -   Deep RAG: 複数の情報源を組み合わせて包括的な回答を生成します。
-   **柔軟な情報管理**:
    -   論文への柔軟なタグ付け機能（理解度、重要度、カスタムタグ）があります。
    -   論文ごとにメモを残すことができます。
-   **パーソナライズ機能**:
    -   ユーザーの閲覧履歴や評価に基づいた論文推薦機能も将来的に対応予定です。

## システム構成図

このセクションでは、KnowledgePaperがローカル環境およびクラウド環境でどのように動作するかの構成を示します。

### ローカル実行時

ローカルマシンで開発やテストを行う際のシステム構成です。

```mermaid
graph TD
    A[ユーザー (ブラウザ)] --> B(フロントエンド <br> Next.js - localhost:3000);
    B --> C{バックエンド <br> FastAPI - localhost:8000};
    C --> D[データベース <br> SQLite];
    C --> E[ベクターストア <br> Chroma DB];
    C --> F[LLM API <br> 外部サービス];
```

-   **ユーザー (ブラウザ)**: アプリケーションのユーザーインターフェースを操作します。
-   **フロントエンド (Next.js - localhost:3000)**: ユーザーインターフェースを提供し、バックエンドと通信を行います。
-   **バックエンド (FastAPI - localhost:8000)**: ビジネスロジックを処理し、データベース、ベクターストア、LLM APIと連携します。
    -   フロントエンドからバックエンドへ: APIリクエストを送信します。
    -   バックエンドからデータベースへ: データの読み書きを行います。
    -   バックエンドからベクターストアへ: ベクトル検索やデータ登録を行います。
    -   バックエンドからLLM APIへ: 論文要約やQ&A生成などの処理を依頼します。
-   **データベース (SQLite)**: 論文のメタデータやユーザー情報などを格納します。
-   **ベクターストア (Chroma DB)**: 論文テキストから生成されたAIが意味を理解するための数値表現（ベクトルデータ）を格納し、類似度に基づいた高速な検索を可能にします。
-   **LLM API (外部サービス)**: 大規模言語モデルを利用した機能（要約生成、質問応答など）を提供する外部のAPIサービスです。

### クラウド実行時

Google Cloud RunやSupabaseなどのクラウドサービスを利用して、アプリケーションを公開・運用する際のシステム構成です。

```mermaid
graph TD
    A[ユーザー (ブラウザ)] --> B(フロントエンド <br> Google Cloud Run - Next.js);
    B --> C{バックエンド <br> Google Cloud Run - FastAPI};
    C --> D[データベース <br> Supabase - PostgreSQL];
    C --> E[ベクターストア <br> BigQuery Vector Search];
    C --> F[LLM API <br> 外部サービス];
```

-   **ユーザー (ブラウザ)**: アプリケーションのUIを操作します。
-   **フロントエンド (Google Cloud Run - Next.js)**: Google Cloud Run上で動作するNext.jsアプリケーションです。ユーザーインターフェースを提供し、バックエンドと通信を行います。
-   **バックエンド (Google Cloud Run - FastAPI)**: Google Cloud Run上で動作するFastAPIアプリケーションです。ビジネスロジックを処理し、データベース、ベクターストア、LLM APIと連携します。
    -   フロントエンドからバックエンドへ: APIリクエストを送信します。
    -   バックエンドからデータベースへ: データの読み書きを行います。
    -   バックエンドからベクターストアへ: ベクトル検索やデータ登録を行います。
    -   バックエンドからLLM APIへ: 論文要約やQ&A生成などの処理を依頼します。
-   **データベース (Supabase - PostgreSQL)**: Supabaseによって提供されるPostgreSQLデータベースです。論文のメタデータやユーザー情報などを格納します。
-   **ベクターストア (BigQuery Vector Search)**: Google Cloud BigQueryのベクトル検索機能です。論文テキストから生成されたベクトルデータを格納し、大規模データに対してもスケーラブルな類似度検索を可能にします。
-   **LLM API (外部サービス)**: 大規模言語モデルを利用した機能（要約生成、質問応答など）を提供する外部のAPIサービスです。

## 利用方法 (各ページ機能解説)

このセクションでは、KnowledgePaperの各ページの機能と使い方について詳しく説明します。

### 1. ホームページ (`/`)

-   **概要:**
    アプリケーションにアクセスすると最初に表示されるメインページです。ここからKnowledgePaperの各主要機能へ簡単にアクセスできます。
-   **主要機能へのリンク:**
    -   ページ上部や目立つ位置に、「論文を追加」「論文一覧」「RAG検索」といった主要機能へ直接移動するためのリンクボタンが配置されています。これらをクリックすることで、目的の機能ページへすぐにジャンプできます。
    -   その他、最近追加された論文のリストやお知らせなどが表示されることもあります。

### 2. 論文追加ページ (`/papers/add`)

-   **概要:**
    新しい論文の情報をKnowledgePaperに登録するための専用ページです。主にArXivの公開URLを使って論文情報を簡単に取り込む方法と、Hugging Face Papersで話題の論文をチェックして取り込む方法が提供されています。
-   **ArXiv URLからのインポート機能:**
    1.  **URLの入力:** ページ内にある「ArXiv URL」と書かれたテキスト入力フィールドに、登録したいArXiv論文のURL (例: `https://arxiv.org/abs/2310.06825` や `https://arxiv.org/pdf/2310.06825.pdf`) をコピー＆ペーストします。
    2.  **情報取得:** URL入力フィールドの横や下にある「URLから論文情報を取得」といったボタンをクリックします。すると、システムが自動的にArXivのサーバーと通信し、論文のタイトル、著者名リスト、概要 (Abstract)、発行日といったメタデータを取得し、ページ内の対応する各フィールド（「タイトル」「著者」「概要」など）に自動で表示します。
    3.  **内容確認と編集:** 自動入力された情報を確認し、もし誤りや不足があれば、各フィールドは直接手で編集することも可能です。
    4.  **登録実行:** 全ての情報の確認・編集が終わったら、「論文情報を登録」や「保存」といった名称のボタンをクリックします。これにより、入力された論文情報がKnowledgePaper内のあなたのデータベースに正式に保存されます。同時に、バックグラウンド処理としてAIがこの論文の内容に基づいた要約の生成を開始します（通常、数分で完了しますが、サーバーの混雑状況や論文の長さによって多少時間がかかることもあります）。
-   **Hugging Face Papersからの自動インポート機能:**
    -   この機能は、Hugging Faceの論文セクションで注目されている新しい論文やトレンド論文をシステムが定期的に（または管理者が手動でトリガーすることにより）チェックし、その中から関連性が高いと判断された論文を自動的にあなたのKnowledgePaperの論文リストに追加候補として表示したり、直接追加したりするものです。
    -   ページ内に「トレンド論文を取得」や「Hugging Faceからインポート」のようなボタンが設置されている場合、それをクリックすることで、手動で最新のトレンド論文のリストを読み込み、選択してインポートすることができます。
    -   **メリット:** あなた自身が常に新しい論文情報を探し回る必要がなくなり、話題の論文やあなたの興味分野に近い論文がシステムによって推薦・追加されるため、効率的な情報収集が可能です。

### 3. 論文一覧ページ (`/papers`)

-   **概要:**
    このページでは、あなたがKnowledgePaperにこれまでに登録した全ての論文を一覧形式で確認し、様々な方法で管理することができます。
-   **表示項目:**
    一覧の各行が一件の論文に対応しており、通常、以下の情報が列ごとに表示されます。
    -   **タイトル:** 論文の正式なタイトルです。多くの場合、このタイトル部分がクリック可能なリンクになっており、クリックするとその論文の詳細ページ (`/papers/[論文ID]`) へ移動します。
    -   **ArXiv ID:** ArXivで公開されている論文の場合、その固有ID (例: `2310.06825`) が表示されます。このID自体が、元のArXivの論文ページへのハイパーリンクになっていることが多いです。
    -   **発行日:** 論文が正式に公開された日付。
    -   **追加日:** あなたがこの論文をKnowledgePaperに登録した日付。
    -   **一言要約:** AIが論文内容を非常に短く（通常は1行から数行程度で）まとめたものです。論文の主要なテーマや結論を素早く把握するのに役立ちます。
    -   **メモ:** あなたがその論文に対して個人的に記入したメモの冒頭部分（最初の数文字や一行目など）が表示されます。メモの全文は論文詳細ページで確認・編集できます。
    -   **タグ:** その論文にあなたが設定した「理解度タグ」（例: `⭐お気に入り`, `未読`, `処理中`など）や「分野タグ」（例: `LLM`, `画像認識`, `強化学習`など）が、色分けされたラベルなどで分かりやすく表示されます。
-   **ソート機能:**
    -   一覧の各列のヘッダー部分（「タイトル」「発行日」「追加日」といった項目名が書かれている部分）は、クリックすることで並び替えのキーとして機能します。
    -   例えば、「発行日」ヘッダーを一度クリックすると発行日が古い順（昇順）に、もう一度クリックすると新しい順（降順）に、論文リスト全体が瞬時に並び替えられます。
-   **フィルタリング機能:**
    -   **タグによる絞り込み:**
        -   ページの上部やサイドバーなどに、あなたが利用している「理解度タグ」や「分野タグ」の一覧が表示されています。特定のタグ（例えば `✅理解した` や `Diffusion Model`）をクリックすると、そのタグが付与された論文だけに絞り込んで一覧に表示することができます。
        -   複数のタグを選択した場合の動作（AND検索：選択した全てのタグを持つ論文のみ表示、OR検索：選択したいずれかのタグを持つ論文を表示）は、専用の切り替えスイッチや設定オプションで指定できる場合があります。
    -   **興味なし論文の表示/非表示:**
        -   「興味なし」という特別なタグを付けた論文を、一覧から一時的に隠すためのスイッチ（例: 「"興味なし" 論文を非表示にする」というチェックボックスやトグルボタン）が用意されていることがあります。これを利用すると、現在の関心からは外れた論文を除外して、リストをより見やすくできます。
-   **ページネーション:**
    -   登録されている論文の数が多く、一覧が長くなる場合、一度に全ての論文を表示するのではなく、複数のページに分割して表示されます。
    -   通常、一覧の最下部（場合によっては最上部にも）に、ページ番号（例: `1`, `2`, `3`, `...`, `10`）や、「< 前へ」「次へ >」といったナビゲーション用のボタンが表示されます。これらをクリックすることで、他のページに収録されている論文リストへ移動できます。
-   **論文ごとのアクション:**
    -   **詳細ページへ移動:** 前述の通り、一覧中の各論文の「タイトル」部分などをクリックすることで、その論文のより詳細な情報が確認できる専用ページ (`/papers/[論文のID]`) へジャンプします。
    -   **クイックアクション (もしあれば):**
        -   各論文の行の右端や、マウスオーバーした際に、小さなアイコンボタン（例: タグを編集するための鉛筆アイコン、論文情報を削除するためのゴミ箱アイコンなど）が表示されることがあります。これらを利用すると、詳細ページにわざわざ移動しなくても、一覧画面から直接「興味なし」タグを素早く付けたり、不要になった論文情報を削除したりといった操作が可能です。
-   **リコメンド機能:**
    -   ページ上部などに、「リコメンド」や「おすすめ論文を表示」といった名前のボタンが設置されていることがあります。
    -   このボタンをクリックすると、システムはあなたが過去に「⭐お気に入り」としてマークした論文、頻繁に閲覧している論文のトピック傾向、あるいは事前に設定したあなたの興味関心分野などを総合的に分析します。
    -   その分析結果に基づいて、あなたがまだあまり注目していないかもしれないものの、興味を持つ可能性が高いとシステムが判断した他の登録済み論文をピックアップし、それらの論文には「Recommended」という特別なタグを付与したり、一覧上で背景色を変えたりして目立つように表示します。これにより、新たな発見を促します。

### 4. 論文詳細ページ (`/papers/[id]`)

-   **概要:**
    論文一覧ページで特定の論文を選択（クリック）すると、この論文詳細ページが表示されます。このページでは、選択した一つの論文に関するあらゆる情報を集約して確認できるだけでなく、AIを活用した様々なインタラクティブな機能を使って論文の理解を深めることができます。
-   **論文メタデータの表示:**
    -   ページのもっとも目立つ上部エリアには、論文の基本的な書誌情報、すなわち「タイトル」「著者名リスト（全員分）」「概要 (Abstract) の全文」「発行日」などが、見やすくレイアウトされて表示されます。
    -   多くの場合、「ArXivで見る」というリンクや、論文ID（例: `arXiv:2310.06825`）自体がクリック可能なリンクになっており、これをクリックすると、その論文が掲載されている元のArXivのウェブページが新しいブラウザタブで開かれます。これにより、オリジナルのPDFや関連情報にいつでも簡単にアクセスできます。
-   **AIによる生成要約:**
    -   この論文のためにAIが自動的に生成した「要約」が表示されます。このAI要約は、論文全体の主要なポイントや貢献、結論などをコンパクトにまとめたもので、全文を読む時間がない場合でも論文の核心を素早く効率的に把握するのに非常に役立ちます。
    -   **要約の再生成機能:**
        -   もし最初に表示されたAI要約が期待した内容でなかったり、少し視点を変えた要約が読みたい場合には、要約を新しく作り直すことができます。
        -   ページ内には「要約設定」や「AIモデル選択」といったセクションがあり、そこには利用可能なAIモデルの種類がリスト（例えば、`Google: Gemini-Flash`, `OpenAI: GPT-4-mini (Legacy)` のような形式で、プロバイダ名とモデル名が記載されたドロップダウンメニューなど）で表示されています。ここから、要約生成に使用したいAIモデルを選びます。
        -   さらに、より専門的なユーザー向けに、AIの応答の「性格」を微調整するためのパラメータ設定が可能な場合もあります。例えば、「temperature」（通常0から1の範囲で、値が低いほど決定的で一貫性のある出力、高いほど多様で創造的な出力になる傾向）や、「top_p」（生成に使用する単語の選択範囲を確率的に制御する値）といった数値を入力フィールドで指定できることがあります。
        -   これらの設定を変更した後、「要約を再生成」や「更新」といったボタンを押すと、AIは新しい設定に基づいて再度論文の要約を生成し、画面上の要約表示を更新します。
-   **論文全文テキスト:**
    -   システムが論文のPDFファイルなどから全文のテキスト情報を抽出し、保存に成功している場合、このエリアに論文の本文全体がスクロール可能な形式で表示されることがあります。
    -   これにより、ユーザーはアプリケーションを離れることなく論文全体を読み進めたり、ブラウザの標準機能であるページ内検索（通常は Ctrl+F または Cmd+F キーで起動）を使って特定のキーワードやフレーズを本文中から効率的に探し出したりすることが可能になります。
-   **ユーザーメモ:**
    -   この論文を読んで気づいたこと、自分の考察や解釈、未解決の疑問点、関連する他の論文への参照、後で確認したい事項など、あなた自身の個人的な情報を自由に書き留めておくための専用のテキスト入力エリアです。
    -   「メモを編集」ボタン（または鉛筆の形をしたアイコンなど）をクリックすると、テキストエリアが編集可能な状態になり、自由に文字を入力したり、既存のメモを修正したりできます。「保存」ボタン（またはフロッピーディスクのアイコンなど）を押すと、入力した内容がシステムに保存され、次回この論文詳細ページを開いた際にも同じメモが表示されます。
-   **タグ管理:**
    -   この論文に対して、あなたの現在の理解度や今後のアクションプランを示す「理解度タグ」（例: `⭐お気に入り` (特に重要), `未読`, `読み途中`, `✅完全に理解した`, `❌興味なし` など）や、論文の内容や研究分野を分類するための「分野タグ」（例: `自然言語処理`, `画像生成モデル`, `ロボティクス`, `医療AI` など）を自由に追加したり、既に付いているタグを削除したりすることができます。
    -   通常、ページには現在この論文に付いているタグのリストがカラフルなラベルなどで表示されています。既存のタグをクリックすることで選択を解除（タグを外す）したり、あるいは「新しいタグを追加」といったテキスト入力フィールドに新しいタグ名（例: `Transformerアーキテクチャ`）を入力してエンターキーを押すか追加ボタンをクリックすることで、自分だけのカスタムタグを新しく作成し、この論文に付与することができます。タグを効果的に整理・活用することで、後で論文一覧ページで目的の論文群を効率的に検索・フィルタリングできるようになります。
-   **論文内容に関するチャット (AIアシスタント):**
    -   この論文の内容に関して、より深く理解したい特定のポイントや、読んでも解消しなかった疑問点がある場合に、AIアシスタントに直接自然言語で質問できるインタラクティブなチャット機能がページ内に埋め込まれています。
    -   **AIモデルの選択:**
        -   このチャット応答を生成するAIも、上記の要約生成機能と同様に、利用可能なAIモデルのリスト（例: `Google: Gemini Pro 1.5`, `OpenAI: GPT-3.5-turbo`, `Anthropic: Claude 3 Sonnet` など、プロバイダ名と具体的なモデル名が表示されたドロップダウンメニューなど）からユーザーが自由に選択できます。モデルによって、回答の得意な質問タイプや応答の文体、情報量などが異なる場合があります。
        -   ここでも、temperatureやtop_pといった専門的なパラメータを調整して、AIの応答の仕方をより細かくユーザーの好みに合わせてコントロールできるオプションが提供される場合があります。
    -   **チャットの利用:**
        -   チャットウィンドウの下部（またはそれに類する場所）にあるテキスト入力ボックスに、論文に関する具体的な質問（例: 「この論文で提案されている "X-Attentional Network" の構造について、図2を参照しながらもう少し詳しく説明してください」「セクション4.2で述べられている実験結果の統計的有意性について、著者はどのように考察していますか？」など）を入力し、「送信」ボタン（多くは紙飛行機のアイコンなど）をクリックします。
        -   AIアシスタントは、現在表示されている論文のテキスト情報やメタデータを主な参照源としながら、あなたの質問に対する回答を生成し、チャットウィンドウ内に新しいメッセージとして表示します。
        -   過去のあなたからの質問とAIからの回答は、一般的なチャットアプリのように画面上に時系列で順番に表示されるため、一連の会話の流れを追いながら、文脈に基づいた連続的な質問をしたり、AIの回答に対してさらに深掘りする質問をしたりすることが可能です。

### 5. RAG検索ページ (`/rag`)

-   **概要:**
    RAG (Retrieval Augmented Generation) 検索ページは、KnowledgePaperの最も強力で先進的な機能の一つです。このページでは、あなたがシステムに登録した個々の論文情報だけでなく、それらデータベース全体を横断的に検索対象とします。さらに、必要に応じてインターネット上の広範な情報源からもリアルタイムに関連情報を検索・取得し、それらの多様な情報を統合・参照しながら、あなたの質問に対してAIが文脈を深く理解した上で包括的かつ洞察に富んだ回答を生成することを目指しています。単にキーワードに一致する論文をリストアップするだけでなく、複数の論文や情報源にまたがるような複雑な問いに対しても、AIが論理的なつながりを見つけ出し、新たな知識や視点を提供してくれる可能性があります。
-   **チャットセッション管理:**
    -   RAG検索における一連の質問とAIの回答のやり取りは、「チャットセッション」という単位で管理・保存されます。
    -   ページ上部や、画面の左側にあるサイドパネルなどに「新しいチャットを開始」や「新規セッション作成」といったボタンがあり、これをクリックすることで、まっさらな状態から新しい研究テーマや質問についての会話（検索セッション）を始めることができます。
    -   過去に行った検索セッションは、通常、サイドパネルなどにリストとして自動的に保存されます。リストの各項目には、セッションの開始日時や、AIが自動生成した（あるいはユーザーが手動で編集した）会話のテーマを示すタイトルが表示されることが多いです。それぞれのセッションをクリックすることで、以前の会話の続きから検索を再開したり、過去の検索結果やAIとの詳細な対話内容を後からじっくりと見返したりすることができます。
-   **検索モードの選択:**
    あなたの質問の具体的な内容や、調査の深さ、目的の性質に合わせて、いくつかの異なる検索モードを選択できます。これらのモードは通常、チャット入力エリアの上部やサイドバーに設置されたドロップダウンメニューやラジオボタン群などを使って切り替えることができます。
    -   **Simpleモード (シンプル検索):**
        -   比較的簡単な質問や、特定の情報源（例：論文データベースのみ、またはウェブ検索のみ）に絞って迅速に回答を得たい場合に最適なモードです。このモードでは、ユーザーが次に説明する「情報源選択（ツール）」を明示的に選択して検索を実行します。
    -   **Deep Researchモード (詳細調査):**
        -   ある特定のトピックや研究テーマについて、より深く、多角的に情報を収集・分析したい場合に利用します。このモードを選択して質問を投げかけると、AIは質問内容を解釈した後、自律的にウェブ検索を複数回、異なるキーワードや角度から実行し、インターネット上から広範な関連情報を収集・分析します。そして、それらの多様な情報源から得られた知見を統合し、より詳細なレポート形式の回答や、複数の視点を比較・対照した考察、あるいは新たな研究の方向性を示唆するような、掘り下げた内容を生成しようと試みます。
    -   **Deep RAGモード (詳細DB検索 - β版など):**
        -   このモードは、特にあなたがKnowledgePaperに登録・蓄積してきた論文データベース内の情報を徹底的に活用し、深掘りすることに特化しています。複数の論文にまたがるような複雑な問い、例えば「過去5年間のX分野におけるY技術の進化の系譜を、主要な貢献論文を引用しながら概説せよ」といった質問に対して、AIがデータベース内を横断的に検索・分析し、関連性の高い論文群を特定。それらの内容を統合・要約して、学術的なレビューに近い形の回答を生成することを目指す、より高度な処理を行うモードです。開発途上（ベータ版）の機能として提供されていることが多く、最高のパフォーマンスを得るためには論文データベースの質と量が重要になります。
-   **ツール選択 (Simpleモード時):**
    Simpleモードで検索を行う際には、AIが情報を参照する「情報源」または「ツール」をユーザーが明示的に選択（または組み合わせて利用）することができます。
    -   **論文DB検索 (RAG):**
        -   このツール（通常はチェックボックスやトグルスイッチでON/OFF）を選択すると、AIはあなたがKnowledgePaperにこれまでに登録した全論文の要約や本文（システムがテキストデータとしてアクセス可能な範囲）の中から、現在の質問に最も関連性の高い箇所や論文全体を効率的に探し出します。そして、その見つけ出した情報を主要な根拠として回答を生成します。
    -   **ウェブ検索 (Search):**
        -   このツールを選択すると、AIはGoogle、Bing、あるいはTavily AIなどの外部検索エンジンAPIを介して、インターネット全体からあなたの質問に関連する情報をリアルタイムに検索します。最新のニュース記事、ブログ投稿、学術以外のウェブサイトなど、あなたの論文DBにはまだ含まれていない可能性のある新しい情報や広範なトピックについての情報を得るのに非常に役立ちます。
    -   これらのツールは、UI上で複数同時に選択できるようになっている場合があり、その場合はAIが両方の情報源（あなたの論文DBとウェブ全体）を考慮に入れて、より網羅的な回答を生成しようとします。
-   **検索対象タグの選択 (論文DB検索利用時):**
    -   「論文DB検索 (RAG)」ツールを利用する際に、検索の範囲をより絞り込むために、あなたが論文に付与した特定の「分野タグ」（例: `LLM`, `Medical AI`, `Robotics`, `Quantum Computing`）を持つ論文群だけに検索対象を限定するオプションが提供されることがあります。
    -   これにより、例えば「LLM」というタグを選択した上で質問をすれば、AIはLLM関連の論文のみを対象としてRAG検索を実行するため、あなたの関心のない分野の論文からのノイズ情報を排除し、より専門的で関連性の高い情報を効率的に得ることが期待できます。タグ選択は、通常、ドロップダウンメニュー、チェックボックスリスト、あるいはクリック可能なタグクラウドといった形式でUI上に表示されます。
-   **AIモデルの選択:**
    -   RAG検索全体の思考プロセス（どの情報をどの程度重視し、どのように組み合わせて論理を構築するかなど）や、最終的なユーザーへの回答文を生成するAIも、利用可能なモデルのリストから選択することができます。このリストには、プロバイダ名（例: Google, OpenAI, Anthropic）、具体的なモデル名（例: Gemini 1.5 Pro, GPT-4 Turbo, Claude 3 Opus）、場合によってはそのモデルのバージョンなどが表示されます。
    -   ここでも、temperature (応答のランダム性・創造性の度合い) や top_p (生成に使用する単語の確率的選択範囲) といった、より専門的なパラメータをユーザーが調整することで、AIの応答のスタイル（より厳密で事実に基づいたものか、より多様で示唆に富むものかなど）をある程度コントロールできる場合があります。
-   **質問入力と回答表示:**
    1.  ページ下部（または中央など、目立つ位置）にあるメインのチャット入力ボックス（大きなテキストエリア）に、あなたが調査したい内容、解決したい疑問、あるいはAIに分析・要約してほしいトピックなどを、できるだけ具体的かつ自然な文章で入力し、「送信」ボタン（多くは紙飛行機のアイコンや「質問する」というラベル）をクリックします。
    2.  システムは、あなたが選択した検索モード（Simple, Deep Research, Deep RAG）、情報源ツール（論文DB, ウェブ検索）、検索対象タグ、AIモデル、および設定したパラメータなどに基づいて、複雑な内部処理（質問の意図解釈、関連情報の検索・収集、収集した情報に基づいた文脈理解、論理的な回答の組み立て、最終的な応答文の生成など）を実行します。この処理には、内容の複雑さや情報源の量によって数秒から数十秒、場合によってはそれ以上かかることもあります。
    3.  処理が完了すると、AIによって生成された回答が、チャットエリアに新しいメッセージとして表示されます。
    4.  **参照元情報の表示:**
        -   生成された回答には、多くの場合、その回答を構成する上でAIが重要と判断し参照した情報源（具体的にどの論文のどのセクションやページ番号を参照したか、どのウェブサイトのどの記事や段落を参考にしたかなど）へのリンクや、関連する引用箇所が一緒に表示されます。
        -   これにより、ユーザーはAIの回答の信頼性を自分自身で客観的に検証したり、提示された元情報を直接たどってさらに深く学習を進めたりすることができます。参照元情報は、回答文中に小さな番号付きの角括弧（例: [1], [2]）で示され、回答の最後やサイドパネルなどにその番号に対応する詳細な出典リストが表示される、といった形式が一般的です。
-   **埋め込みモデル再構築ページへのリンク (もしあれば):**
    -   「論文DB検索 (RAG)」機能の検索精度や関連性の高さは、論文のテキスト情報をコンピュータが効率的に比較・検索できるように数値ベクトル（AIが単語や文章の意味を数値で表現したもの。ベクトル埋め込みとも言います）に変換する「埋め込みモデル」の性能や、そのベクトルデータが常に最新の状態に保たれているかどうかに大きく依存します。新しい論文を追加したり、既存の論文情報が更新されたりした場合、これらのベクトルデータも再計算・更新するメンテナンス作業が理想的です。
    -   もしこのRAG検索ページ内や設定ページなどに、「埋め込みを更新」「ベクトルDBを再構築」といった名称のリンクやボタンがあり、そのリンク先が `/admin/embedding` のような管理者向けパスのページである場合、そこから全論文（または選択した論文）のベクトルデータを再計算・更新する処理を開始できる可能性があります。この機能は通常、システムの管理者権限を持つユーザー向けに提供されます。

これらの説明が、KnowledgePaperを効果的に活用するための一助となれば幸いです。アプリケーションは日々進化するため、実際の画面表示や細かい操作方法は、ここで説明したものと若干異なる場合があるかもしれませんが、基本的な考え方は共通しているはずです。

## 環境構築 (ローカル実行)

このセクションでは、ご自身のローカルマシンでKnowledgePaperを動かすための環境構築手順を説明します。

### 前提条件

以下のソフトウェアがインストールされていることを確認してください。

-   Python (バージョン3.9 以降を推奨します)
-   Node.js (バージョン18.x 以降を推奨します) と pnpm (npm, yarnでも代用可能ですが、このドキュメントではpnpmを基準に説明します)
-   Docker (オプションですが、関連するDocker Compose設定がある場合に利用します)

### リポジトリのクローン

まず、本アプリケーションのソースコードをご自身のマシンにコピーします。

```bash
git clone https://github.com/your-username/knowledge-paper.git # 正しいリポジトリURLに置き換えてください
cd knowledge-paper
```

### バックエンド設定

次に、バックエンドサーバー (FastAPI) の設定を行います。

```bash
cd backend
python -m venv .venv # Python仮想環境を作成します
# Windowsの場合:
# .venv\Scripts\activate
# macOS/Linuxの場合:
# source .venv/bin/activate
pip install -r requirements.txt # 必要なライブラリをインストールします
```

### フロントエンド設定

続いて、フロントエンド (Next.js) の設定を行います。

```bash
cd .. # リポジトリのルートディレクトリに戻ります
pnpm install # 必要なライブラリをインストールします
```

### 環境変数設定

アプリケーションの動作に必要な設定情報を環境変数として設定します。
リポジトリのルートディレクトリに `.env` という名前のファイルを作成してください。
もし `.env.example` ファイルが存在する場合は、それをコピーして `.env` にリネームし、各項目を適切に設定してください。存在しない場合は、以下の内容を参考に `.env` ファイルを新規に作成し、必要な値を設定してください。

```env
# 実行環境 (必須: "local" または "cloud")
DEPLOY="local"

# --- ローカル実行時のみ必要な設定 ---
# データベース設定 (SQLite)
SQLITE_FILE_PATH="database/sqlite/db.sqlite3" # デフォルトのパスです。必要に応じて変更してください。

# ローカルベクターストア設定 (デフォルトはChroma DB)
LOCAL_VECTOR_STORE_TYPE="chroma" # 他のタイプも将来的にサポートする可能性があります。
LOCAL_VECTOR_STORE_PERSIST_DIR="./database/vector_db" # Chroma DBのデータを永続化するディレクトリです。
LOCAL_VECTOR_STORE_COLLECTION="papers"               # Chroma DBのコレクション名です。

# ローカル実行時のEmbeddingモデル設定
# Embeddingモデルとは、AIが文章の意味を数値のベクトルとして表現するために使うものです。
LOCAL_EMBEDDING_PROVIDER="Google" # デフォルトはGoogleのモデルです。"OpenAI_Base" なども選択可能です。
LOCAL_EMBEDDING_MODEL_NAME="models/text-embedding-004" # Googleの場合のモデル名です。

# --- クラウド実行時のみ必要な設定 (詳細はクラウド実行のセクションを参照) ---
# SUPABASE_DB_USER=""
# SUPABASE_DB_PASSWORD=""
# SUPABASE_DB_HOST=""
# SUPABASE_DB_PORT=""
# SUPABASE_DB_NAME=""
# BQ_VECTOR_STORE_PROJECT_ID=""
# BQ_VECTOR_STORE_DATASET_NAME=""
# BQ_VECTOR_STORE_TABLE_NAME=""
# BQ_VECTOR_STORE_LOCATION=""
# BQ_EMBEDDING_PROVIDER="Google"
# BQ_EMBEDDING_MODEL_NAME="models/text-embedding-004"
# GOOGLE_APPLICATION_CREDENTIALS_JSON=""

# --- 共通で必要な設定 ---
# LLM APIキー (利用するサービスのAPIキーを設定してください)
# これらのキーは、論文の要約生成やAIチャット機能などで使用します。
GOOGLE_API_KEY="YOUR_GOOGLE_API_KEY"
OPENAI_API_KEY="YOUR_OPENAI_API_KEY"
OPENROUTER_API_KEY="YOUR_OPENROUTER_API_KEY"
XAI_API_KEY="YOUR_XAI_API_KEY"
# ANTHROPIC_API_KEY="YOUR_ANTHROPIC_API_KEY" # Anthropicのモデルを利用する場合は、config.yamlの設定に合わせてコメントを解除し、キーを設定してください。

# NextAuth.js 設定 (ユーザー認証関連)
NEXTAUTH_URL="http://localhost:3000" # アプリケーションのURLです。
NEXTAUTH_SECRET="YOUR_NEXTAUTH_SECRET" # セキュリティのための重要な秘密鍵です。openssl rand -hex 32 コマンドなどで生成したランダムな文字列を設定してください。
GITHUB_ID="YOUR_GITHUB_OAUTH_CLIENT_ID" # GitHub認証を利用する場合に設定します (オプション)。
GITHUB_SECRET="YOUR_GITHUB_OAUTH_CLIENT_SECRET" # GitHub認証を利用する場合に設定します (オプション)。
GOOGLE_CLIENT_ID="YOUR_GOOGLE_OAUTH_CLIENT_ID" # Google認証を利用する場合に設定します (オプション)。
GOOGLE_CLIENT_SECRET="YOUR_GOOGLE_OAUTH_CLIENT_SECRET" # Google認証を利用する場合に設定します (オプション)。

# CORS設定 (バックエンドAPIへのアクセス許可)
CORS_ORIGINS="http://localhost:3000" # フロントエンドのURLを許可します。クラウド環境では適宜変更してください。
```

**【注意】**
-   `NEXTAUTH_SECRET` は必ず設定してください。セキュリティに関わるため、推測されにくい強力なランダム文字列を使用することを強く推奨します。
-   各種APIキーは、あなたが利用したいLLMプロバイダのサービスに登録し、発行されたAPIキーを設定してください。
-   GitHubやGoogleなどのOAuth認証を利用してログイン機能を使いたい場合は、各プロバイダの開発者コンソールでアプリケーションを登録し、発行されたクライアントIDとクライアントシークレットを設定する必要があります。

### データベースの初期化

バックエンドのFastAPIアプリケーションは、初回起動時に `db.init_db()` という関数を呼び出します。この関数は、環境変数 `SQLITE_FILE_PATH` で指定されたパスにSQLiteデータベースファイルと、アプリケーションに必要なテーブル群を自動的に作成します。特別な手動操作は不要です。

### アプリケーションの起動

以下の手順で、バックエンドサーバーとフロントエンドサーバーをそれぞれ起動します。

1.  **バックエンドサーバーの起動:**
    新しいターミナルウィンドウ（またはタブ）を開き、`backend` ディレクトリに移動します。仮想環境が有効化されていることを確認してから、以下のコマンドを実行してください。
    ```bash
    cd backend
    uvicorn main:app --host 0.0.0.0 --port 8000 --reload
    ```
    これにより、バックエンドAPIサーバーが `http://localhost:8000` で起動します。`--reload`オプションにより、コード変更時にサーバーが自動的に再起動します。

2.  **フロントエンドサーバーの起動:**
    別の新しいターミナルウィンドウ（またはタブ）を開き、リポジトリのルートディレクトリ（例: `knowledge-paper`）で以下のコマンドを実行してください。
    ```bash
    pnpm dev
    ```
    これにより、フロントエンドの開発サーバーが `http://localhost:3000` で起動します。

3.  **ブラウザでアクセス:**
    ウェブブラウザを開き、アドレスバーに `http://localhost:3000` と入力してアクセスすると、KnowledgePaperアプリケーションが表示されます。

### 補足

-   ローカル実行環境では、デフォルトでデータベースとしてSQLite、論文のベクトル情報を格納するベクターストアとしてChroma DBが使用されるように設定されています。
-   環境変数 `LOCAL_VECTOR_STORE_TYPE` を変更することで、Chroma DB以外のローカルベクターストアも利用可能になる予定ですが、現時点ではChroma DBを前提としています。他のベクターストアを利用する場合の設定方法は、将来的に各ベクターストアの公式ドキュメントなどを参照する必要が出てくるかもしれません。

## 環境構築 (クラウド実行 - Google Cloud Run)

このセクションでは、Google Cloud Runを使用してKnowledgePaperアプリケーションをクラウド環境にデプロイ（公開）する方法の概要を説明します。
バックエンドAPIとフロントエンドUIを、それぞれ別のCloud Runサービスとしてデプロイすることを想定しています。
データベースにはSupabaseが提供するPostgreSQLを、ベクターストアにはGoogle Cloud BigQueryのVector Search機能を利用する構成例です。

### 概要

このセクションでは、Google Cloud Run を使用してアプリケーションをデプロイする方法を説明します。
バックエンドとフロントエンドをそれぞれ別のCloud Runサービスとしてデプロイします。
データベースにはSupabase (PostgreSQL)、ベクターストアにはBigQuery Vector Searchを使用します。

### 前提条件

以下の準備が整っていることを確認してください。

-   Google Cloud Platform (GCP) のアカウントをお持ちであること。
-   Google Cloud SDK (gcloud CLI) がご自身のマシンにインストールされ、GCPアカウントと連携設定済みであること。
-   Dockerがご自身のマシンにインストール済みであること。
-   pnpm (またはnpm/yarn) がインストール済みであること。
-   Supabaseのアカウントをお持ちであること（または他のPostgreSQL互換データベースを用意できること）。

### 1. Supabaseの設定 (データベース)

Supabaseを利用して、アプリケーションのデータを保存するPostgreSQLデータベースを準備します。

1.  **Supabaseプロジェクトの作成:**
    Supabaseの公式サイトにアクセスし、新しいプロジェクトを作成します。
2.  **接続情報の取得:**
    作成したプロジェクトのデータベース設定ページ（通常、「Project Settings」内の「Database」セクション）から、以下の接続情報を取得し、安全な場所に控えておきます。これらは後ほどCloud Runの環境変数として設定します。
    -   ホスト名 (例: `db.xxxxxxxxxx.supabase.co` - これを `SUPABASE_DB_HOST` 環境変数に設定)
    -   ポート番号 (通常 `5432` - これを `SUPABASE_DB_PORT` 環境変数に設定)
    -   データベース名 (通常 `postgres` - これを `SUPABASE_DB_NAME` 環境変数に設定)
    -   ユーザー名 (通常 `postgres` - これを `SUPABASE_DB_USER` 環境変数に設定)
    -   パスワード (プロジェクト作成時に設定したもの、または後からリセットして取得可能 - これを `SUPABASE_DB_PASSWORD` 環境変数に設定)
3.  **テーブルスキーマの作成:**
    Supabaseのダッシュボード内にあるSQL Editor（「SQL Editor」>「New query」）を使用して、アプリケーションが必要とするテーブルスキーマを作成します。
    主なテーブル構造は以下の通りです。詳細なカラム定義やデータ型、リレーションシップ（テーブル間の関連付け）については、バックエンドのソースコード内にある `backend/models.py` ファイル内の各クラス定義を参照してください。
    -   `users`: アプリケーションのユーザー情報を格納します。
    -   `paper_metadata`: 論文のタイトル、著者、公開URL、PDFへのパスなどのメタデータを格納します。
    -   `generated_summaries`: AIによって生成された各論文の要約を保存します。
    -   `user_paper_links`: 各ユーザーと各論文の関連情報（理解度タグ、カスタムタグ、個人的なメモなど）を紐付けて管理します。
    -   `chat_messages`: 論文詳細ページでのAIとのチャット履歴を保存します。
    -   `rag_sessions`: RAG検索ページでの一連の検索セッション情報を管理します。
    -   `rag_messages`: 各RAG検索セッション内でのユーザーの質問とAIの回答の履歴を保存します。

    （将来的には、データベースのテーブル構造を自動的に作成・更新するためのマイグレーションスクリプトの提供を予定しています。それまでは、お手数ですが `backend/models.py` を参考に手動でテーブルを作成してください。）

### 2. BigQuery Vector Searchの設定 (ベクターストア)

登録された論文のテキスト情報をAIが効率的に検索できるようにするため、BigQuery Vector Searchをベクターストアとして利用します。

1.  **BigQuery APIの有効化:**
    GCPコンソールで、利用するGCPプロジェクトを選択し、「APIとサービス」のダッシュボードから BigQuery API を有効化します。
2.  **データセットの作成:**
    GCPコンソールのBigQueryページで、新しくデータセットを作成します。
    -   データセットID (例: `knowledgepaper_vector_store`) を決定します。このIDを、後でバックエンドサービスの環境変数 `BQ_VECTOR_STORE_DATASET_NAME` に設定します。
    -   データセットのロケーション (例: `asia-northeast1` - 東京リージョン) を選択します。このロケーション名を環境変数 `BQ_VECTOR_STORE_LOCATION` に設定します。
3.  **ベクトル検索用テーブルの作成:**
    作成したデータセット内に、論文のベクトルデータを格納するためのテーブルを作成します。
    -   テーブル名 (例: `papers_embeddings`) を決定します。このテーブル名を環境変数 `BQ_VECTOR_STORE_TABLE_NAME` に設定します。
    -   テーブルスキーマ（列の定義）は、主に以下のようになります。
        -   `id`: STRING型 (各ベクトルデータのユニークなID、UUIDなどが望ましい)
        -   `content`: STRING型 (検索対象となる元テキストの断片)
        -   `embedding`: ARRAY<FLOAT64>型 (テキストのベクトル表現。数値の配列です)
        -   `user_id`: STRING型 (オプション。ユーザーごとにデータを分離したい場合に使用)
        -   `paper_metadata_id`: STRING型 (このベクトルデータがどの論文に属するかを示す、`paper_metadata`テーブルのIDとの関連付け)
        -   `generated_summary_id`: STRING型 (オプション。もし要約文のベクトルも格納する場合、関連する要約ID)
        -   `created_at`: TIMESTAMP型 (このベクトルデータが作成された日時)
        -   その他、検索時のフィルタリング条件として使用したいメタデータフィールド（例: 分野タグなど）を適宜追加できます。
    -   ベクトル検索の際の距離計算方法（例: `COSINE` や `EUCLIDEAN`）やベクトルの次元数（例: Googleの`text-embedding-004`モデルの場合は768次元）は、主にバックエンドのアプリケーション設定ファイル (`config.yaml` 内の `bq_vector_store.distance_strategy` や `embedding_config.dimensions`) で定義されます。テーブル作成時にこれらを厳密に指定する必要はありませんが、後述のベクトルインデックス作成時にこれらの設定が考慮されます。
    -   (より詳細なテーブルスキーマ定義や、効率的な検索のためのベクトルインデックス作成方法については、バックエンドのソースコード `backend/vectorstore/manager.py` 内の `BigQueryVectorStoreManager` クラス、特に `create_table_if_not_exists` メソッドやインデックス作成に関連するメソッドの実装を参照してください。)
4.  **サービスアカウントの作成と設定 (セキュリティ):**
    Cloud RunサービスがBigQueryに安全にアクセスできるように、専用のサービスアカウントを設定します。
    -   GCPコンソールの「IAMと管理」セクション内にある「サービスアカウント」ページで、新しいサービスアカウントを作成します。
    -   作成したサービスアカウントに対して、以下のIAMロール（権限）を付与します:
        -   `BigQuery データ編集者 (roles/bigquery.dataEditor)`
        -   `BigQuery ユーザー (roles/bigquery.user)`
    -   このサービスアカウントのキー（JSON形式のファイル）を作成し、ご自身のマシンにダウンロードします。
    -   **【重要】** このダウンロードしたJSONファイルの内容全体を、後述するCloud Runのバックエンドサービスの環境変数 `GOOGLE_APPLICATION_CREDENTIALS_JSON` に設定する方法があります。しかし、より安全な方法として、Cloud Runサービスの「セキュリティ」タブで、作成したサービスアカウントを「実行サービスアカウント」として直接関連付けることを強く推奨します。この場合、`GOOGLE_APPLICATION_CREDENTIALS_JSON` 環境変数の設定は不要になります。

### 3. バックエンドのデプロイ (Cloud Run)

通常、リポジトリルートにある `cloudbuild.yaml` (または `cloudbuild.example.yaml` を元に作成したもの) を利用して、以下のコマンド一発でバックエンドとフロントエンドのイメージビルド、プッシュ、Cloud Runへのデプロイ（または更新）が自動的に行われます。`TAG_NAME`、バックエンドおよびフロントエンドのサービス名、リージョンなどの変数は、ご自身の環境に合わせて適宜設定する必要があります。`cloudbuild.example.yaml` の `substitutions` セクションや各ステップの引数などを参考に、必要な変数をコマンドラインから渡してください。

```bash
gcloud builds submit --config cloudbuild.yaml . --substitutions=TAG_NAME=latest,_BACKEND_SERVICE_NAME=knowledgepaper-backend,_FRONTEND_SERVICE_NAME=knowledgepaper-frontend,_REGION=asia-northeast1
```

もし `cloudbuild.yaml` を利用しない場合や、個別にステップを実行したい場合は、以下の手順で手動デプロイも可能です。

#### `cloudbuild.yaml` を使用しない場合の手順:

1.  **Dockerイメージのビルド:**
    リポジトリのルートディレクトリ（例: `knowledge-paper`）で、以下のコマンドを実行してバックエンド用のDockerイメージをビルドします。`[PROJECT_ID]` は、ご自身の実際のGCPプロジェクトIDに置き換えてください。
    ```bash
    docker build -t gcr.io/[PROJECT_ID]/knowledgepaper-backend:latest -f backend/Dockerfile .
    ```
2.  **Dockerイメージのプッシュ:**
    ビルドしたイメージを、Google Container Registry (GCR) または Artifact Registry にプッシュ（アップロード）します。
    ```bash
    docker push gcr.io/[PROJECT_ID]/knowledgepaper-backend:latest
    ```
3.  **Cloud Runサービスの設定とデプロイ:**
    -   GCPコンソールでCloud Runのページを開き、「サービスの作成」を選択します。
    -   「既存のコンテナ イメージから1つのリビジョンをデプロイする」を選び、上記でプッシュしたイメージのURL (例: `gcr.io/[PROJECT_ID]/knowledgepaper-backend:latest`) を指定します。
    -   サービス名 (例: `knowledgepaper-backend`) を設定します。
    -   デプロイするリージョンを選択します (例: `asia-northeast1` - SupabaseやBigQueryのリージョンと合わせることを推奨します)。
    -   **環境変数の設定:** 「変数とシークレット」タブで、以下の環境変数を設定します。機密情報（パスワードやAPIキー）は、可能であればSecret Managerに保存し、そこから参照するように設定することを強く推奨します。
        -   `DEPLOY="cloud"`
        -   `SUPABASE_DB_USER`: (上記「1. Supabaseの設定」で取得したユーザー名)
        -   `SUPABASE_DB_PASSWORD`: (上記「1. Supabaseの設定」で取得したパスワード) - Secret Manager経由を推奨
        -   `SUPABASE_DB_HOST`: (上記「1. Supabaseの設定」で取得したホスト名)
        -   `SUPABASE_DB_PORT`: (上記「1. Supabaseの設定」で取得したポート番号)
        -   `SUPABASE_DB_NAME`: (上記「1. Supabaseの設定」で取得したデータベース名)
        -   `BQ_VECTOR_STORE_PROJECT_ID="[YOUR_GCP_PROJECT_ID]"` (BigQueryが属するGCPプロジェクトID)
        -   `BQ_VECTOR_STORE_DATASET_NAME="knowledgepaper_vector_store"` (上記「2. BigQuery Vector Searchの設定」で作成したデータセット名)
        -   `BQ_VECTOR_STORE_TABLE_NAME="papers_embeddings"` (上記「2. BigQuery Vector Searchの設定」で作成したテーブル名)
        -   `BQ_VECTOR_STORE_LOCATION="asia-northeast1"` (上記「2. BigQuery Vector Searchの設定」で指定したリージョン)
        -   `BQ_EMBEDDING_PROVIDER="Google"` (または `OpenAI_Base` など、`config.yaml`の`embedding_config`セクションと合わせてください)
        -   `BQ_EMBEDDING_MODEL_NAME="models/text-embedding-004"` (Googleの場合のモデル名例。`config.yaml`と合わせてください)
        -   `GOOGLE_APPLICATION_CREDENTIALS_JSON`: (上記「2. BigQuery Vector Searchの設定」でサービスアカウントキーJSONの内容全体を貼り付けるか、サービスアカウントを直接関連付けた場合は不要です) - Secret Manager経由を推奨
        -   各種LLM APIキー (`GOOGLE_API_KEY`, `OPENAI_API_KEY`, `OPENROUTER_API_KEY`, `XAI_API_KEY` など、ローカル実行時と同様に利用するサービスのキー) - Secret Manager経由を推奨
        -   `CORS_ORIGINS`: フロントエンドのデプロイ先URL (例: `https://frontend-service-name-xxxxxx-an.a.run.app`)。複数設定する場合はカンマ区切りで指定します。
        -   その他、`config.yaml`ファイル内の設定を上書きしたい場合は、対応する環境変数をここで設定できます (例: `LOG_LEVEL="INFO"`)。
    -   コンテナがリッスンするポートを `8000` (またはバックエンドのDockerfileで `EXPOSE` されているポート番号) に設定します。
    -   「ネットワーキング」タブで、必要に応じてVPCコネクタを設定します (例えば、Supabaseデータベースへの接続がプライベートIP経由の場合など)。
    -   「セキュリティ」タブで、「実行サービスアカウント」として、上記「2. BigQuery Vector Searchの設定」で作成・設定したBigQueryアクセス用のサービスアカウントを指定することを推奨します。
    -   必要に応じて、CPUの割り当て、メモリサイズ、リクエストのタイムアウト時間、スケーリング設定 (最小/最大インスタンス数など) を細かく構成します。
    -   「作成」ボタンをクリックしてデプロイを開始します。
4.  **サービスURLの確認:**
    デプロイが正常に完了すると、Cloud Runサービスに一意の公開URLが割り当てられます (例: `https://knowledgepaper-backend-xxxxxx-an.a.run.app`)。このURLを控えておき、次のフロントエンドの設定でバックエンドAPIのエンドポイントとして使用します。

### 4. フロントエンドのデプロイ (Cloud Run)

`cloudbuild.yaml` を使用する場合、バックエンドのデプロイに続いてフロントエンドのデプロイも自動的に行われます（上記 `gcloud builds submit` コマンド例を参照）。

もし `cloudbuild.yaml` を利用しない場合や、個別にステップを実行したい場合は、以下の手順で手動デプロイも可能です。

#### `cloudbuild.yaml` を使用しない場合の手順:

1.  **Dockerイメージのビルド:**
    リポジトリのルートディレクトリで、以下のコマンドを実行してフロントエンド用のDockerイメージをビルドします。`[PROJECT_ID]` はご自身のGCPプロジェクトIDに置き換えてください。フロントエンド用のDockerfile (`Dockerfile.frontend`など) を指定します。
    ```bash
    docker build -t gcr.io/[PROJECT_ID]/knowledgepaper-frontend:latest -f Dockerfile.frontend .
    ```
2.  **Dockerイメージのプッシュ:**
    ビルドしたイメージをGCRまたはArtifact Registryにプッシュします。
    ```bash
    docker push gcr.io/[PROJECT_ID]/knowledgepaper-frontend:latest
    ```
3.  **Cloud Runサービスの設定とデプロイ:**
    -   GCPコンソールでCloud Runを開き、再度「サービスの作成」を選択します。
    -   上記でプッシュしたフロントエンドのイメージURL (`gcr.io/[PROJECT_ID]/knowledgepaper-frontend:latest`) を指定します。
    -   サービス名 (例: `knowledgepaper-frontend`) を設定します。
    -   リージョンを選択します (バックエンドサービスと同じリージョンを選択することを推奨します)。
    -   **環境変数の設定:**
        -   `NEXT_PUBLIC_BACKEND_URL`: 上記「3. バックエンドのデプロイ」で控えておいたバックエンドサービスの公開URLを設定します。
        -   `NEXTAUTH_URL`: これからデプロイされるこのフロントエンドサービス自身の公開URLを設定します。Cloud Runは自動でHTTPS URLを提供するため、通常は設定不要な場合もありますが、OAuth認証プロバイダのコールバックURLとして正確なURLを登録する必要があるため、デプロイ後に表示される完全なURL (例: `https://knowledgepaper-frontend-xxxxxx-an.a.run.app`) をここに設定することを推奨します。
        -   `NEXTAUTH_SECRET`: (ローカル実行時と同様に `openssl rand -hex 32` などで生成した強力なランダム文字列) - Secret Manager経由での設定を推奨します。
        -   OAuth認証を利用する場合:
            -   `GITHUB_ID`, `GITHUB_SECRET`
            -   `GOOGLE_CLIENT_ID`, `GOOGLE_CLIENT_SECRET`
            -   これらの情報もSecret Manager経由での設定を推奨します。また、各OAuthプロバイダのアプリケーション設定画面で、コールバックURL (リダイレクトURI) を、この新しいフロントエンドサービスのURL (例: `https://knowledgepaper-frontend-xxxxxx-an.a.run.app/api/auth/callback/github`) に忘れずに更新してください。
    -   コンテナがリッスンするポートを `3000` (またはフロントエンドのDockerfileで `EXPOSE` されているポート番号) に設定します。
    -   必要に応じて、CPU、メモリ、スケーリング設定などを構成します。
    -   「作成」ボタンをクリックしてデプロイを開始します。
4.  **動作確認:**
    デプロイされたフロントエンドのURLにブラウザでアクセスし、アプリケーションが正常に動作し、バックエンドAPIと通信できていることを確認します。

### 補足

-   **`cloudbuild.yaml` のカスタマイズ:**
    提供されている `cloudbuild.example.yaml` はあくまで一例です。実際のデプロイでは、サービス名、リージョン、環境変数、シークレットの参照方法、インスタンスタイプ、スケーリング設定など、多くの項目をご自身のプロジェクトに合わせてカスタマイズする必要があります。`cloudbuild.yaml` 内のコメントや各ステップの引数をよく確認し、適切に変更してください。
-   **スキーマ管理 (データベースとベクターストア):**
    -   Supabase (PostgreSQL) のテーブルスキーマ（テーブル構造やカラム定義など）の変更管理には、Supabaseが提供するマイグレーション機能や、Alembic (Pythonバックエンド用) やPrisma Migrate (もし利用していれば) といった外部のスキーママイグレーションツールの利用を検討してください。これにより、スキーマ変更の履歴管理や再現が容易になります。
    -   BigQueryのテーブルスキーマやベクトルインデックス定義の変更は、手動で行うか、`bq` コマンドラインツールを使ったスクリプト、あるいはTerraformのようなIaC (Infrastructure as Code) ツールを用いてコードとして管理することを推奨します。
-   **コスト管理:**
    Cloud Run, Supabase, BigQuery, 各LLM APIは、基本的に従量課金制のサービスです。利用状況に応じてコストが発生するため、各サービスの料金体系をよく確認し、不要なリソースはこまめに削除するなど、コスト管理には十分注意してください。GCPの予算アラート機能を設定し、予期せぬ高額請求を防ぐことも重要です。
-   **Secret Management (機密情報の管理):**
    APIキーやデータベースのパスワードといった機密情報は、Cloud Runサービスの環境変数に直接平文で設定する代わりに、Google Cloud Secret Managerのような専用のシークレット管理サービスを使用して安全に保管し、Cloud Runサービスからはそのシークレットへの参照として設定することを強く推奨します。これにより、セキュリティが大幅に向上します。

## 環境変数一覧

以下は、本アプリケーションをセットアップし実行する際に設定が必要となる主要な環境変数の一覧です。これらの変数は、アプリケーションの動作モード（ローカル開発かクラウド展開か）、使用するデータベース、ベクターストア、外部APIサービスへの接続情報などを制御します。

| 環境変数名                             | 説明                                                                                                                               | 設定例                                                                                       | 対象     |
| -------------------------------------- | ---------------------------------------------------------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------- | -------- |
| `DEPLOY`                               | アプリケーションのデプロイメント環境を指定します。`local` または `cloud` のいずれかを設定します。                                                | `local`                                                                                      | L/C      |
| `SQLITE_FILE_PATH`                     | ローカル実行時に使用するSQLiteデータベースファイルのパスを指定します。                                                                         | `database/sqlite/db.sqlite3`                                                                 | L        |
| `LOCAL_VECTOR_STORE_TYPE`              | ローカル実行時に使用するベクターストアのタイプを指定します（例: `chroma`）。                                                                     | `chroma`                                                                                     | L        |
| `LOCAL_VECTOR_STORE_PERSIST_DIR`       | ローカルベクターストア（Chroma DBなど）のデータを永続的に保存するディレクトリのパスを指定します。                                                     | `./database/vector_db`                                                                       | L        |
| `LOCAL_VECTOR_STORE_COLLECTION`        | ローカルベクターストア（Chroma DBなど）内で使用するコレクション（テーブルのようなもの）の名前を指定します。                                               | `papers`                                                                                     | L        |
| `LOCAL_EMBEDDING_PROVIDER`             | ローカル実行時に使用するEmbeddingモデル（文章をベクトル化するAIモデル）の提供元を指定します（例: `Google`, `OpenAI_Base`）。                  | `Google`                                                                                     | L        |
| `LOCAL_EMBEDDING_MODEL_NAME`           | ローカル実行時に使用する具体的なEmbeddingモデルの名前を指定します（例: Googleの`models/text-embedding-004`）。                               | `models/text-embedding-004`                                                                  | L        |
| `SUPABASE_DB_USER`                     | クラウド実行時、Supabaseデータベースに接続するためのユーザー名を指定します。                                                                      | `postgres`                                                                                   | C        |
| `SUPABASE_DB_PASSWORD`                 | Supabaseデータベースに接続するためのパスワードを指定します。セキュリティのため、直接書き込まずSecret Manager等からの参照を推奨します。                  | `YOUR_SUPABASE_PASSWORD`                                                                     | C        |
| `SUPABASE_DB_HOST`                     | Supabaseデータベースのホスト名を指定します。                                                                                           | `db.xxxxxxxxxx.supabase.co`                                                                  | C        |
| `SUPABASE_DB_PORT`                     | Supabaseデータベースのポート番号を指定します。                                                                                           | `5432`                                                                                       | C        |
| `SUPABASE_DB_NAME`                     | Supabaseデータベースのデータベース名を指定します。                                                                                       | `postgres`                                                                                   | C        |
| `BQ_VECTOR_STORE_PROJECT_ID`           | クラウド実行時、BigQuery Vector Searchを使用するGCPプロジェクトのIDを指定します。                                                              | `your-gcp-project-id`                                                                        | C        |
| `BQ_VECTOR_STORE_DATASET_NAME`         | BigQuery Vector Searchで使用するデータセットの名前を指定します。                                                                         | `knowledgepaper_vector_store`                                                                | C        |
| `BQ_VECTOR_STORE_TABLE_NAME`           | BigQuery Vector Searchで使用するテーブルの名前を指定します。                                                                           | `papers_embeddings`                                                                          | C        |
| `BQ_VECTOR_STORE_LOCATION`             | BigQuery Vector Searchのデータセットおよびテーブルが配置されているGCPリージョンを指定します。                                                      | `asia-northeast1`                                                                            | C        |
| `BQ_EMBEDDING_PROVIDER`                | クラウド実行時（BigQuery Vector Search利用時）のEmbeddingモデルの提供元を指定します。                                                      | `Google`                                                                                     | C        |
| `BQ_EMBEDDING_MODEL_NAME`              | クラウド実行時（BigQuery Vector Search利用時）の具体的なEmbeddingモデルの名前を指定します。                                                     | `models/text-embedding-004`                                                                  | C        |
| `GOOGLE_APPLICATION_CREDENTIALS_JSON`  | GCPのサービスアカウントキー（JSON形式）の内容全体。Cloud Runバックエンドでは、Secret Manager経由での設定またはサービスアカウントの直接関連付けを強く推奨します。 | (JSON文字列全体、またはSecret Managerのリソースパス)                                             | C        |
| `GOOGLE_API_KEY`                       | Google AI Studioなどで取得した、GoogleのAIモデル（Geminiなど）を利用するためのAPIキー。                                                       | `YOUR_GOOGLE_API_KEY`                                                                        | L/C      |
| `OPENAI_API_KEY`                       | OpenAIのプラットフォームで取得した、GPTモデルなどを利用するためのAPIキー。                                                                      | `YOUR_OPENAI_API_KEY`                                                                        | L/C      |
| `OPENROUTER_API_KEY`                   | OpenRouter経由で様々なLLMを利用する場合に設定するAPIキー。                                                                                  | `YOUR_OPENROUTER_API_KEY`                                                                    | L/C      |
| `XAI_API_KEY`                          | XAI (Grokなど) のモデルを利用する場合に設定するAPIキー。                                                                                  | `YOUR_XAI_API_KEY`                                                                           | L/C      |
| `ANTHROPIC_API_KEY`                    | AnthropicのClaudeモデルなどを利用する場合に設定するAPIキー（`config.yaml`内の設定と合わせて利用）。                                               | `YOUR_ANTHROPIC_API_KEY`                                                                     | L/C      |
| `NEXT_PUBLIC_BACKEND_URL`              | フロントエンドアプリケーションが通信するバックエンドAPIサーバーのURL。                                                                           | ローカル: `http://localhost:8000`, クラウド: `https://your-backend-service-url.a.run.app`       | L/C      |
| `NEXTAUTH_URL`                         | NextAuth.js（ユーザー認証ライブラリ）が使用するアプリケーションの正規URL。OAuthのコールバックURLなどで重要になります。                                | ローカル: `http://localhost:3000`, クラウド: `https://your-frontend-service-url.a.run.app`    | L/C      |
| `NEXTAUTH_SECRET`                      | NextAuth.jsのセッション情報やCSRFトークンの暗号化に使用される非常に重要な秘密鍵。推測困難なランダム文字列を設定してください。                       | (例: `openssl rand -hex 32` コマンドで生成した文字列)                                           | L/C      |
| `GITHUB_ID`                            | GitHubアカウントを利用したOAuth認証を有効にする場合に、GitHubから発行されるクライアントID。                                                     | `YOUR_GITHUB_CLIENT_ID`                                                                      | L/C      |
| `GITHUB_SECRET`                        | GitHub OAuth認証のクライアントシークレット。                                                                                              | `YOUR_GITHUB_CLIENT_SECRET`                                                                  | L/C      |
| `GOOGLE_CLIENT_ID`                     | Googleアカウントを利用したOAuth認証を有効にする場合に、Google Cloud Consoleから発行されるクライアントID。                                         | `YOUR_GOOGLE_CLIENT_ID`                                                                      | L/C      |
| `GOOGLE_CLIENT_SECRET`                 | Google OAuth認証のクライアントシークレット。                                                                                              | `YOUR_GOOGLE_CLIENT_SECRET`                                                                  | L/C      |
| `CORS_ORIGINS`                         | バックエンドAPIサーバーがCORS（Cross-Origin Resource Sharing）リクエストを許可するオリジン（ドメイン）のリスト。カンマ区切りで複数指定可能です。        | ローカル: `http://localhost:3000`, クラウド: `https://your-frontend-service-url.a.run.app` | L/C      |

**凡例:**
-   **L**: ローカル実行環境で主に設定される変数
-   **C**: クラウド実行環境 (Google Cloud Runなど) で主に設定される変数
-   **L/C**: ローカル・クラウド両方の環境で設定が必要となる可能性がある変数

<!--
This is a [Next.js](https://nextjs.org) project bootstrapped with [`create-next-app`](https://nextjs.org/docs/app/api-reference/cli/create-next-app).

## Getting Started

First, run the development server:

```bash
npm run dev
# or
yarn dev
# or
pnpm dev
# or
bun dev
```

Open [http://localhost:3000](http://localhost:3000) with your browser to see the result.

You can start editing the page by modifying `app/page.tsx`. The page auto-updates as you edit the file.

This project uses [`next/font`](https://nextjs.org/docs/app/building-your-application/optimizing/fonts) to automatically optimize and load [Geist](https://vercel.com/font), a new font family for Vercel.

## Learn More

To learn more about Next.js, take a look at the following resources:

- [Next.js Documentation](https://nextjs.org/docs) - learn about Next.js features and API.
- [Learn Next.js](https://nextjs.org/learn) - an interactive Next.js tutorial.

You can check out [the Next.js GitHub repository](https://github.com/vercel/next.js) - your feedback and contributions are welcome!

## Deploy on Vercel

The easiest way to deploy your Next.js app is to use the [Vercel Platform](https://vercel.com/new?utm_medium=default-template&filter=next.js&utm_source=create-next-app&utm_campaign=create-next-app-readme) from the creators of Next.js.

Check out our [Next.js deployment documentation](https://nextjs.org/docs/app/building-your-application/deploying) for more details.
-->
